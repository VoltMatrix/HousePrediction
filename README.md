# HousePrediction


This project uses the California Housing dataset to predict median house prices for different districts using Machine Learning. The goal is to build a regression model that can accurately estimate house prices based on features like income, location, and number of rooms.

The entire process includes:

Data downloading & loading

Data exploration & visualization

Feature engineering & preprocessing

Model training & evaluation

Hyperparameter tuning (GridSearchCV)

Final performance testing with confidence intervals

ğŸ¯ Objective
Predict house prices using:

ğŸ˜ï¸ Median income

ğŸ“… Housing age

ğŸ›ï¸ Total rooms

ğŸŒŠ Ocean proximity (categorical)

ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Population & household data

We use these features to train regression models and evaluate which one gives the most accurate price predictions.

ğŸ“¦ Dataset
ğŸ“ Source: California Housing Dataset

ğŸ“Š Features: Median income, rooms, location, population, etc.

ğŸ¯ Target: median_house_value (the value we want to predict)

ğŸ› ï¸ ML Tools & Libraries
pandas, numpy â€“ Data manipulation

matplotlib, seaborn â€“ Visualizations

scikit-learn â€“ ML models and preprocessing

GridSearchCV â€“ Hyperparameter tuning

RandomForestRegressor â€“ Best performing model

ğŸ”„ Workflow Overview
1ï¸âƒ£ Data Loading
Downloaded from GitHub and extracted

Loaded using pandas.read_csv()

2ï¸âƒ£ Data Exploration
Histograms and scatter plots

Correlation analysis

Geographical visualizations (longitude vs latitude)

3ï¸âƒ£ Feature Engineering
Created new features:

rooms_per_household

population_per_household

bedrooms_per_room

4ï¸âƒ£ Preprocessing Pipeline
Handled missing values using SimpleImputer

One-hot encoded categorical data (ocean_proximity)

Feature scaling with StandardScaler

Custom CombinedAttributesAdder transformer added engineered features

5ï¸âƒ£ Model Training & Evaluation
Trained three models:

Linear Regression

Decision Tree Regressor

Random Forest Regressor âœ… (Best performance)

Evaluated using:

Training RMSE

Cross-validation

Final test set performance

6ï¸âƒ£ Hyperparameter Tuning
Tuned RandomForestRegressor with GridSearchCV

Evaluated top features using feature importances

7ï¸âƒ£ Final Evaluation
Used the best model from GridSearchCV

Calculated:

RMSE on the test set

95% Confidence Interval using scipy.stats

ğŸ“ˆ Results
Model	RMSE (Cross-Validation)
Linear Regression	High error
Decision Tree	Overfits
âœ… Random Forest	Best accuracy and generalization

ğŸ¤– How to Use
Prepare new housing data in the same format.

Run it through the full_pipeline for preprocessing.

Use the trained model:

python
Copy
Edit
prediction = final_model.predict(prepared_data)
ğŸ“‚ Project Structure
bash
Copy
Edit
ğŸ“ housing-price-predictor
â”‚
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ housing/
â”‚       â””â”€â”€ housing.csv
â”œâ”€â”€ housing_model.py  # Main ML script
â”œâ”€â”€ README.md         # This file
â””â”€â”€ requirements.txt  # Libraries used
ğŸ“Œ Future Improvements
Add XGBoost or LightGBM for even better performance

Deploy using Streamlit or Flask

Save and load models using joblib

Add interactive visualization dashboards

ğŸ§  Key Learnings
Hands-on experience with a full ML pipeline

Feature engineering really boosts performance

Importance of cross-validation and model tuning

Pipelines help make your code modular and reusable


